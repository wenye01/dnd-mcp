# ä»»åŠ¡å…­å®æ–½æŒ‡å—

## æ–‡æ¡£ä¿¡æ¯

- **ç‰ˆæœ¬**: v1.0
- **åˆ›å»ºæ—¥æœŸ**: 2025-02-04
- **é€‚ç”¨èŒƒå›´**: ä»»åŠ¡å…­ï¼ˆLLM é›†æˆï¼‰
- **å‰ææ¡ä»¶**: ä»»åŠ¡å››å·²å®Œæˆ

---

## ğŸ“‹ å®æ–½æ­¥éª¤

### é˜¶æ®µ1ï¼šä¿®å¤å¯¹è¯ä¸Šä¸‹æ–‡ï¼ˆğŸ”´ P0 - å¿…é¡»ï¼‰

**æ—¶é—´**: 2-3å°æ—¶

**æ­¥éª¤1.1**: ä¿®æ”¹ `internal/api/handler/message.go`

**ä½ç½®**: SendMessage å‡½æ•°

**å½“å‰ä»£ç **ï¼ˆç¬¬71-73è¡Œï¼‰:
```go
llmResp, err := h.llmClient.Chat(c.Request.Context(), &llm.ChatRequest{
    Messages: []llm.Message{{Role: "user", Content: req.Content}},
})
```

**ä¿®æ”¹ä¸º**:
```go
// 1. åŠ è½½å†å²æ¶ˆæ¯ï¼ˆæœ€è¿‘ 50 æ¡ï¼‰
history, err := h.messageStore.List(c.Request.Context(), sessionID, 50)
if err != nil {
    c.JSON(http.StatusInternalServerError, gin.H{
        "error": gin.H{
            "code":    "INTERNAL_ERROR",
            "message": "åŠ è½½å†å²æ¶ˆæ¯å¤±è´¥",
        },
    })
    return
}

// 2. æ„å»º LLM ä¸Šä¸‹æ–‡
messages := []llm.Message{
    {
        Role:    "system",
        Content: "ä½ æ˜¯ DND æ¸¸æˆçš„ DM(åœ°ä¸‹åŸä¸»)ã€‚è´Ÿè´£æè¿°åœºæ™¯ã€æ‰®æ¼” NPCã€åˆ¤æ–­è§„åˆ™ã€æ¨è¿›å‰§æƒ…ã€‚",
    },
}

// 3. æ·»åŠ å†å²æ¶ˆæ¯
for _, msg := range history {
    messages = append(messages, llm.Message{
        Role:    msg.Role,
        Content: msg.Content,
    })
}

// 4. æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
messages = append(messages, llm.Message{
    Role:    "user",
    Content: req.Content,
})

// 5. è°ƒç”¨ LLM
llmResp, err := h.llmClient.Chat(c.Request.Context(), &llm.ChatRequest{
    Messages:    messages,
    Temperature: 0.7,
})
```

**éªŒè¯**:
```bash
# ä½¿ç”¨ Mock æ¨¡å¼æµ‹è¯•
export LLM_PROVIDER=mock
./bin/dnd-client.exe server start

# å‘é€ç¬¬ä¸€æ¡æ¶ˆæ¯
curl -X POST http://localhost:8080/api/sessions/{id}/chat \
  -H "Content-Type: application/json" \
  -d '{"content":"ä½ å¥½","player_id":"player-123"}'

# å‘é€ç¬¬äºŒæ¡æ¶ˆæ¯ï¼ˆåº”è¯¥èƒ½è®°ä½ç¬¬ä¸€æ¡ï¼‰
curl -X POST http://localhost:8080/api/sessions/{id}/chat \
  -H "Content-Type: application/json" \
  -d '{"content":"æˆ‘åˆšæ‰è¯´äº†ä»€ä¹ˆï¼Ÿ","player_id":"player-123"}'
```

**é¢„æœŸç»“æœ**: Mock LLM å¯èƒ½æ— æ³•æ­£ç¡®å›ç­”ï¼Œä½†ä¸Šä¸‹æ–‡å·²ä¼ é€’ã€‚

---

### é˜¶æ®µ2ï¼šæ‰©å±• LLM é…ç½®ï¼ˆâš ï¸ P1 - åº”è¯¥ï¼‰

**æ—¶é—´**: 1-2å°æ—¶

**æ­¥éª¤2.1**: æ‰©å±• `pkg/config/config.go`

```go
// Config åº”ç”¨é…ç½®
type Config struct {
    Redis    RedisConfig    `mapstructure:"redis"`
    Postgres PostgresConfig `mapstructure:"postgres"`
    Log      LogConfig      `mapstructure:"log"`
    HTTP     HTTPConfig     `mapstructure:"http"`
    LLM      LLMConfig      `mapstructure:"llm"` // æ–°å¢
}

// LLMConfig LLM é…ç½®
type LLMConfig struct {
    Provider    string  `mapstructure:"provider" env:"LLM_PROVIDER" default:"mock"`
    APIKey      string  `mapstructure:"api_key" env:"LLM_API_KEY" default:""`
    Model       string  `mapstructure:"model" env:"LLM_MODEL" default:"gpt-4"`
    MaxTokens   int     `mapstructure:"max_tokens" env:"LLM_MAX_TOKENS" default:"4096"`
    Temperature float64 `mapstructure:"temperature" env:"LLM_TEMPERATURE" default:"0.7"`
    Timeout     int     `mapstructure:"timeout" env:"LLM_TIMEOUT" default:"30"`
}
```

**æ­¥éª¤2.2**: æ·»åŠ é…ç½®éªŒè¯

```go
// Validate éªŒè¯é…ç½®
func (c *Config) Validate() error {
    // ... ç°æœ‰éªŒè¯ ...

    // éªŒè¯ LLM é…ç½®
    if c.LLM.Provider != "mock" && c.LLM.Provider != "openai" {
        return fmt.Errorf("æ— æ•ˆçš„ LLM provider: %s", c.LLM.Provider)
    }

    if c.LLM.Provider == "openai" && c.LLM.APIKey == "" {
        return fmt.Errorf("OpenAI API key ä¸èƒ½ä¸ºç©º")
    }

    return nil
}
```

**éªŒè¯**:
```bash
# æµ‹è¯•é…ç½®åŠ è½½
export LLM_PROVIDER=mock
./bin/dnd-client.exe server start

# åº”è¯¥è¾“å‡º: "ä½¿ç”¨ LLM provider: mock"

export LLM_PROVIDER=openai
export LLM_API_KEY=test-key
./bin/dnd-client.exe server start

# åº”è¯¥è¾“å‡º: "ä½¿ç”¨ LLM provider: openai"
```

---

### é˜¶æ®µ3ï¼šå®ç° OpenAI Clientï¼ˆâš ï¸ P1 - åº”è¯¥ï¼‰

**æ—¶é—´**: 3-4å°æ—¶

**æ­¥éª¤3.1**: åˆ›å»º `internal/llm/openai.go`

```go
package llm

import (
    "bytes"
    "context"
    "encoding/json"
    "fmt"
    "io"
    "net/http"
    "time"

    "github.com/dnd-mcp/client/pkg/config"
)

type OpenAIClient struct {
    config     *config.LLMConfig
    httpClient *http.Client
    baseURL    string
    apiKey     string
}

func NewOpenAIClient(cfg *config.LLMConfig) *OpenAIClient {
    return &OpenAIClient{
        config:  cfg,
        baseURL: "https://api.openai.com/v1",
        apiKey:  cfg.APIKey,
        httpClient: &http.Client{
            Timeout: time.Duration(cfg.Timeout) * time.Second,
        },
    }
}

func (c *OpenAIClient) Chat(ctx context.Context, req *ChatRequest) (*ChatResponse, error) {
    // è®¾ç½®é»˜è®¤æ¨¡å‹
    if req.Model == "" {
        req.Model = c.config.Model
    }

    // åºåˆ—åŒ–è¯·æ±‚
    reqBody, err := json.Marshal(req)
    if err != nil {
        return nil, fmt.Errorf("åºåˆ—åŒ–è¯·æ±‚å¤±è´¥: %w", err)
    }

    // åˆ›å»º HTTP è¯·æ±‚
    httpReq, err := http.NewRequestWithContext(ctx, "POST",
        c.baseURL+"/chat/completions",
        bytes.NewReader(reqBody))
    if err != nil {
        return nil, fmt.Errorf("åˆ›å»º HTTP è¯·æ±‚å¤±è´¥: %w", err)
    }

    // è®¾ç½®è¯·æ±‚å¤´
    httpReq.Header.Set("Content-Type", "application/json")
    httpReq.Header.Set("Authorization", "Bearer "+c.apiKey)

    // å‘é€è¯·æ±‚
    resp, err := c.httpClient.Do(httpReq)
    if err != nil {
        return nil, fmt.Errorf("å‘é€ HTTP è¯·æ±‚å¤±è´¥: %w", err)
    }
    defer resp.Body.Close()

    // æ£€æŸ¥å“åº”çŠ¶æ€
    if resp.StatusCode != http.StatusOK {
        body, _ := io.ReadAll(resp.Body)
        return nil, fmt.Errorf("API è¯·æ±‚å¤±è´¥ (status %d): %s",
            resp.StatusCode, string(body))
    }

    // è§£æå“åº”
    var chatResp ChatResponse
    if err := json.NewDecoder(resp.Body).Decode(&chatResp); err != nil {
        return nil, fmt.Errorf("è§£æå“åº”å¤±è´¥: %w", err)
    }

    return &chatResp, nil
}
```

**æ­¥éª¤3.2**: æ·»åŠ å·¥å‚å‡½æ•°

**ä¿®æ”¹** `internal/llm/client.go`:

```go
// NewClient åˆ›å»º LLM å®¢æˆ·ç«¯
func NewClient(cfg *config.LLMConfig) (LLMClient, error) {
    switch cfg.Provider {
    case "openai":
        if cfg.APIKey == "" {
            return nil, fmt.Errorf("OpenAI API key ä¸èƒ½ä¸ºç©º")
        }
        return NewOpenAIClient(cfg), nil

    case "mock":
        return NewMockLLMClient(), nil

    default:
        return nil, fmt.Errorf("ä¸æ”¯æŒçš„ LLM provider: %s", cfg.Provider)
    }
}
```

---

### é˜¶æ®µ4ï¼šé›†æˆåˆ°æœåŠ¡å™¨ï¼ˆâš ï¸ P1 - åº”è¯¥ï¼‰

**æ—¶é—´**: 1-2å°æ—¶

**æ­¥éª¤4.1**: ä¿®æ”¹ `internal/cli/server.go`

```go
func StartCommand(cmd *cobra.Command, args []string) error {
    // åŠ è½½é…ç½®
    cfg, err := config.Load()
    if err != nil {
        return fmt.Errorf("åŠ è½½é…ç½®å¤±è´¥: %w", err)
    }

    // åˆå§‹åŒ– LLM Clientï¼ˆğŸ†• ä½¿ç”¨å·¥å‚å‡½æ•°ï¼‰
    llmClient, err := llm.NewClient(&cfg.LLM)
    if err != nil {
        return fmt.Errorf("åˆå§‹åŒ– LLM å®¢æˆ·ç«¯å¤±è´¥: %w", err)
    }

    logrus.Infof("ä½¿ç”¨ LLM provider: %s", cfg.LLM.Provider)

    // åˆå§‹åŒ– Redis
    // ... ç°æœ‰ä»£ç  ...

    // åˆ›å»º Handler
    messageHandler := handler.NewMessageHandler(messageStore, sessionStore, llmClient)

    // ... å¯åŠ¨æœåŠ¡å™¨ ...
}
```

---

### é˜¶æ®µ5ï¼šæ‰©å±•ç±»å‹æ”¯æŒ tool_callsï¼ˆâš ï¸ P2 - å¯é€‰ï¼‰

**æ—¶é—´**: 2-3å°æ—¶

**æ­¥éª¤5.1**: æ‰©å±• `internal/llm/types.go`

```go
// ChatRequest èŠå¤©è¯·æ±‚(æ‰©å±•)
type ChatRequest struct {
    Model       string    `json:"model"`
    Messages    []Message `json:"messages"`
    Tools       []Tool    `json:"tools,omitempty"`
    Temperature float64   `json:"temperature,omitempty"`
}

// Tool å·¥å…·å®šä¹‰
type Tool struct {
    Type     string      `json:"type"`
    Function FunctionDef `json:"function"`
}

// FunctionDef å‡½æ•°å®šä¹‰
type FunctionDef struct {
    Name        string                 `json:"name"`
    Description string                 `json:"description"`
    Parameters  map[string]interface{} `json:"parameters"`
}

// ChatResponse èŠå¤©å“åº”(æ‰©å±•)
type ChatResponse struct {
    ID      string   `json:"id"`
    Object  string   `json:"object"`
    Created int64    `json:"created"`
    Model   string   `json:"model"`
    Choices []Choice `json:"choices"`
    Usage   Usage    `json:"usage"`
}

// Choice é€‰æ‹©
type Choice struct {
    Index        int     `json:"index"`
    Message      Message `json:"message"`
    FinishReason string  `json:"finish_reason"`
}

// Usage ä½¿ç”¨ç»Ÿè®¡
type Usage struct {
    PromptTokens     int `json:"prompt_tokens"`
    CompletionTokens int `json:"completion_tokens"`
    TotalTokens      int `json:"total_tokens"`
}

// Message æ¶ˆæ¯(æ‰©å±•)
type Message struct {
    Role       string     `json:"role"`
    Content    string     `json:"content"`
    ToolCalls  []ToolCall `json:"tool_calls,omitempty"`
    ToolCallID string     `json:"tool_call_id,omitempty"`
}

// ToolCall å·¥å…·è°ƒç”¨
type ToolCall struct {
    ID       string       `json:"id"`
    Type     string       `json:"type"`
    Function FunctionCall `json:"function"`
}

// FunctionCall å‡½æ•°è°ƒç”¨
type FunctionCall struct {
    Name      string `json:"name"`
    Arguments string `json:"arguments"` // JSON string
}
```

---

### é˜¶æ®µ6ï¼šå¤„ç† tool_callsï¼ˆâš ï¸ P2 - ä»»åŠ¡ä¸ƒå‡†å¤‡ï¼‰

**æ—¶é—´**: 2-3å°æ—¶

**æ­¥éª¤6.1**: ä¿®æ”¹ Handler æ·»åŠ  tool_calls å¤„ç†

```go
// åœ¨ SendMessage å‡½æ•°ä¸­

// 5. æ£€æŸ¥å“åº”ç±»å‹
if len(llmResp.Choices) == 0 {
    // é”™è¯¯å¤„ç†
}

choice := llmResp.Choices[0]

// 6. åˆ¤æ–­æ˜¯å¦æœ‰ tool_calls
if choice.FinishReason == "tool_calls" && len(choice.Message.ToolCalls) > 0 {
    // å¤„ç†å·¥å…·è°ƒç”¨ï¼ˆä¿å­˜ï¼Œä¸æ‰§è¡Œï¼‰
    return h.handleToolCalls(c, sessionID, choice.Message.ToolCalls)
}

// 7. ä¿å­˜åŠ©æ‰‹æ¶ˆæ¯ï¼ˆçº¯æ–‡æœ¬å“åº”ï¼‰
// ... ç°æœ‰ä»£ç  ...
```

**æ­¥éª¤6.2**: å®ç° handleToolCalls

```go
func (h *MessageHandler) handleToolCalls(c *gin.Context, sessionID string, toolCalls []llm.ToolCall) {
    ctx := c.Request.Context()

    // 1. ä¿å­˜ assistant æ¶ˆæ¯ï¼ˆåŒ…å« tool_callsï¼‰
    assistantMsg := &models.Message{
        ID:        uuid.New().String(),
        SessionID: sessionID,
        Role:      "assistant",
        Content:   "",
        ToolCalls: convertLLMToolCalls(toolCalls),
        CreatedAt: time.Now(),
    }

    if err := h.messageStore.Create(ctx, assistantMsg); err != nil {
        c.JSON(http.StatusInternalServerError, gin.H{
            "error": gin.H{
                "code":    "INTERNAL_ERROR",
                "message": "ä¿å­˜å·¥å…·è°ƒç”¨æ¶ˆæ¯å¤±è´¥",
            },
        })
        return
    }

    // 2. è¿”å›å“åº”ï¼ˆå½“å‰ä»…ä¿å­˜ï¼Œä¸æ‰§è¡Œå·¥å…·ï¼‰
    c.JSON(http.StatusOK, gin.H{
        "id":         assistantMsg.ID,
        "session_id": assistantMsg.SessionID,
        "role":       assistantMsg.Role,
        "tool_calls": assistantMsg.ToolCalls,
        "created_at": assistantMsg.CreatedAt.Format(time.RFC3339),
        "message":    "LLM è¿”å›äº†å·¥å…·è°ƒç”¨ï¼Œç­‰å¾… MCP é›†æˆï¼ˆä»»åŠ¡ä¸ƒï¼‰æ‰§è¡Œ",
    })
}

func convertLLMToolCalls(llmToolCalls []llm.ToolCall) []models.ToolCall {
    toolCalls := make([]models.ToolCall, len(llmToolCalls))
    for i, tc := range llmToolCalls {
        var args map[string]interface{}
        json.Unmarshal([]byte(tc.Function.Arguments), &args)

        toolCalls[i] = models.ToolCall{
            ID:        tc.ID,
            Name:      tc.Function.Name,
            Arguments: args,
        }
    }
    return toolCalls
}
```

---

## ğŸ§ª æµ‹è¯•æ­¥éª¤

### æµ‹è¯•1ï¼šMock æ¨¡å¼ï¼ˆåŸºæœ¬åŠŸèƒ½ï¼‰

```bash
# 1. é…ç½® Mock æ¨¡å¼
export LLM_PROVIDER=mock

# 2. å¯åŠ¨æœåŠ¡å™¨
./bin/dnd-client.exe server start

# 3. åˆ›å»ºä¼šè¯
SESSION_ID=$(curl -X POST http://localhost:8080/api/sessions \
  -H "Content-Type: application/json" \
  -d '{"name":"æµ‹è¯•ä¼šè¯","creator_id":"user-123","mcp_server_url":"http://localhost:9000}' \
  | jq -r '.id')

# 4. å‘é€ç¬¬ä¸€æ¡æ¶ˆæ¯
curl -X POST http://localhost:8080/api/sessions/$SESSION_ID/chat \
  -H "Content-Type: application/json" \
  -d '{"content":"ä½ å¥½","player_id":"player-123"}'

# 5. å‘é€ç¬¬äºŒæ¡æ¶ˆæ¯ï¼ˆæµ‹è¯•ä¸Šä¸‹æ–‡ï¼‰
curl -X POST http://localhost:8080/api/sessions/$SESSION_ID/chat \
  -H "Content-Type: application/json" \
  -d '{"content":"æˆ‘åˆšæ‰è¯´äº†ä»€ä¹ˆï¼Ÿ","player_id":"player-123"}'
```

### æµ‹è¯•2ï¼šçœŸå® OpenAI APIï¼ˆéœ€è¦ API Keyï¼‰

```bash
# 1. é…ç½® OpenAI
export LLM_PROVIDER=openai
export LLM_API_KEY=sk-xxx
export LLM_MODEL=gpt-4

# 2. å¯åŠ¨æœåŠ¡å™¨
./bin/dnd-client.exe server start

# 3. å‘é€æ¶ˆæ¯
curl -X POST http://localhost:8080/api/sessions/{id}/chat \
  -H "Content-Type: application/json" \
  -d '{"content":"ä»‹ç»ä¸€ä¸‹ DND æ¸¸æˆ","player_id":"player-123"}'

# 4. éªŒè¯å¤šè½®å¯¹è¯
# å‘é€: "è¿™ä¸ªæ¸¸æˆæœ‰å“ªäº›èŒä¸šï¼Ÿ"
# å‘é€: "ç¬¬ä¸€ä¸ªèŒä¸šæ˜¯ä»€ä¹ˆï¼Ÿ"
# LLM åº”è¯¥èƒ½ç†è§£ä¸Šä¸‹æ–‡
```

### æµ‹è¯•3ï¼štool_callsï¼ˆéœ€è¦çœŸå® LLMï¼‰

```bash
# 1. ç¡®ä¿ä½¿ç”¨ OpenAI
export LLM_PROVIDER=openai
export LLM_API_KEY=sk-xxx

# 2. å‘é€å¯èƒ½è§¦å‘å·¥å…·è°ƒç”¨çš„æ¶ˆæ¯
curl -X POST http://localhost:8080/api/sessions/{id}/chat \
  -H "Content-Type: application/json" \
  -d '{"content":"æˆ‘è¦æŠ•æ·ä¸€ä¸ª d20 éª°å­","player_id":"player-123"}'

# 3. éªŒè¯å“åº”åŒ…å« tool_calls å­—æ®µ
# æ³¨æ„: å½“å‰åªä¿å­˜ tool_callsï¼Œä¸æ‰§è¡Œ
```

---

## âœ… éªŒæ”¶æ ‡å‡†

### å¿…é¡»å®Œæˆï¼ˆğŸ”´ P0ï¼‰

- [ ] **å¯¹è¯ä¸Šä¸‹æ–‡æ„å»º** - åŠ è½½å†å² 50 æ¡æ¶ˆæ¯
- [ ] **å¤šè½®å¯¹è¯æµ‹è¯•** - LLM èƒ½ç†è§£ä¹‹å‰çš„å¯¹è¯
- [ ] **Mock æ¨¡å¼æ­£å¸¸** - å¼€å‘æµ‹è¯•ä½¿ç”¨ Mock
- [ ] **é…ç½®é©±åŠ¨åˆ‡æ¢** - LLM_PROVIDER ç¯å¢ƒå˜é‡æ§åˆ¶

### åº”è¯¥å®Œæˆï¼ˆâš ï¸ P1ï¼‰

- [ ] **OpenAI Client** - çœŸå® API è°ƒç”¨
- [ ] **LLM é…ç½®ç®¡ç†** - é…ç½®æ–‡ä»¶/ç¯å¢ƒå˜é‡
- [ ] **é”™è¯¯å¤„ç†** - API é”™è¯¯ã€è¶…æ—¶ç­‰
- [ ] **åŸºæœ¬æµ‹è¯•** - å•å…ƒæµ‹è¯• + é›†æˆæµ‹è¯•

### å¯é€‰å®Œæˆï¼ˆâš ï¸ P2ï¼‰

- [ ] **tool_calls è§£æ** - è§£æå¹¶ä¿å­˜å·¥å…·è°ƒç”¨
- [ ] **tool_calls æµ‹è¯•** - ä½¿ç”¨çœŸå® LLM æµ‹è¯•
- [ ] **æµå¼å“åº”** - Streaming APIï¼ˆé¢„ç•™ï¼‰

---

## ğŸ“Š å·¥ä½œé‡è¯„ä¼°

| é˜¶æ®µ | ä»»åŠ¡ | æ—¶é—´ | ä¼˜å…ˆçº§ |
|------|------|------|--------|
| 1 | å¯¹è¯ä¸Šä¸‹æ–‡æ„å»º | 2-3å°æ—¶ | ğŸ”´ P0 |
| 2 | LLM é…ç½®ç®¡ç† | 1-2å°æ—¶ | âš ï¸ P1 |
| 3 | OpenAI Client | 3-4å°æ—¶ | âš ï¸ P1 |
| 4 | æœåŠ¡å™¨é›†æˆ | 1-2å°æ—¶ | âš ï¸ P1 |
| 5 | ç±»å‹æ‰©å±• | 2-3å°æ—¶ | âš ï¸ P2 |
| 6 | tool_calls å¤„ç† | 2-3å°æ—¶ | âš ï¸ P2 |
| **æ€»è®¡ï¼ˆP0+P1ï¼‰** | | **7-11å°æ—¶** | |
| **æ€»è®¡ï¼ˆå« P2ï¼‰** | | **11-17å°æ—¶** | |

---

## ğŸ¯ æ¨èå®æ–½é¡ºåº

### æœ€å°å¯è¡Œç‰ˆæœ¬ï¼ˆMVPï¼‰

**æ—¶é—´**: 7-11å°æ—¶

**åŒ…å«**:
- âœ… é˜¶æ®µ1: å¯¹è¯ä¸Šä¸‹æ–‡æ„å»ºï¼ˆğŸ”´ å¿…é¡»ï¼‰
- âœ… é˜¶æ®µ2: LLM é…ç½®ç®¡ç†
- âœ… é˜¶æ®µ3: OpenAI Client
- âœ… é˜¶æ®µ4: æœåŠ¡å™¨é›†æˆ

**ä¸åŒ…å«**:
- âŒ tool_calls å¤„ç†ï¼ˆç•™åˆ°ä»»åŠ¡ä¸ƒï¼‰
- âŒ æµå¼å“åº”

**ä¼˜ç‚¹**:
- âœ… å¿«é€Ÿå®ç°å¤šè½®å¯¹è¯
- âœ… æ”¯æŒçœŸå® LLM
- âœ… ä¸ºä»»åŠ¡ä¸ƒåšå¥½å‡†å¤‡

---

## ğŸ“ æ³¨æ„äº‹é¡¹

### 1. å‘åå…¼å®¹

- âœ… Mock LLM ä¿æŒä¸å˜
- âœ… ç°æœ‰ API ä¸ä¿®æ”¹
- âœ… é…ç½®æœ‰é»˜è®¤å€¼

### 2. é”™è¯¯å¤„ç†

- âœ… OpenAI API è°ƒç”¨å¤±è´¥
- âœ… é…ç½®é”™è¯¯
- âœ… è¶…æ—¶å¤„ç†
- âœ… Redis æŸ¥è¯¢å¤±è´¥

### 3. æ€§èƒ½è€ƒè™‘

- âœ… å†å²æ¶ˆæ¯é™åˆ¶åœ¨ 50 æ¡
- âœ… Redis æŸ¥è¯¢æ€§èƒ½
- âœ… OpenAI API å“åº”æ—¶é—´ï¼ˆ1-3ç§’ï¼‰

### 4. å®‰å…¨è€ƒè™‘

- âœ… API Key ä¸æš´éœ²åœ¨æ—¥å¿—ä¸­
- âœ… ä½¿ç”¨ç¯å¢ƒå˜é‡
- âœ… é…ç½®æ–‡ä»¶ä¸æäº¤åˆ° Git

---

## ğŸ”— ç›¸å…³æ–‡æ¡£

- `doc/å¼€å‘ä»»åŠ¡å…­.md` - è¯¦ç»†å¼€å‘è®¡åˆ’
- `doc/ä»»åŠ¡å››ä¸ä»»åŠ¡å…­è®¾è®¡åˆç†æ€§åˆ†æ.md` - è®¾è®¡åˆ†æ
- `doc/æ¶æ„ç®€åŒ–è¯´æ˜.md` - æ¶æ„è¯´æ˜
- `doc/DND_MCP_Clientè¯¦ç»†è®¾è®¡.md` - å®Œæ•´è®¾è®¡

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**æœ€åæ›´æ–°**: 2025-02-04
**ç»´æŠ¤è€…**: DND MCP Client å¼€å‘å›¢é˜Ÿ
